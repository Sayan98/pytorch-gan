{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/SharedData/intern_sayan/GAN/MNIST\"\n",
    "!mkdir -p images\n",
    "\n",
    "CUDA = 1\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "\n",
    "img_shape = (1, 28, 28)\n",
    "lr = 1e-4\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train batches: 118, # test batches: 20\n",
      "train image: torch.Size([1, 28, 28])\n",
      "test image: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Test')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6403576c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(DATA_DIR, train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Test Dataloader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(DATA_DIR, train=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"# train batches: {len(train_loader)}, # test batches: {len(test_loader)}\")\n",
    "\n",
    "print(f\"train image: {train_loader.dataset[0][0].size()}\")\n",
    "print(f\"test image: {test_loader.dataset[0][0].size()}\")\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "a = fig.add_subplot(1,2,1)\n",
    "plt.imshow(train_loader.dataset[1][0].reshape(28,28))\n",
    "a.set_title(\"Train\")\n",
    "\n",
    "a = fig.add_subplot(1,2,2)\n",
    "plt.imshow(test_loader.dataset[1][0].reshape(28,28))\n",
    "a.set_title(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        p_value = self.model(img_flat)\n",
    "\n",
    "        return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Generator & Discriminator\n",
    "generator = Generator(latent_dim=latent_dim)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if CUDA:\n",
    "    adversarial_loss.cuda(CUDA)\n",
    "    generator.cuda(CUDA)\n",
    "    discriminator.cuda(CUDA)\n",
    "    \n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    epoch_g_loss, epoch_d_loss = 0,0\n",
    "    delta = time.time()\n",
    "    \n",
    "    for batch_idx, (imgs, _label) in enumerate(train_loader):\n",
    "        if CUDA:\n",
    "            # Adversarial ground truths\n",
    "            valid = torch.autograd.Variable(torch.FloatTensor(imgs.size(0),\n",
    "                                                              1).fill_(1.0).cuda(CUDA),\n",
    "                                            requires_grad=False)\n",
    "            fake = torch.autograd.Variable(torch.FloatTensor(imgs.size(0),\n",
    "                                                             1).fill_(0.0).cuda(CUDA),\n",
    "                                           requires_grad=False)\n",
    "\n",
    "            # Real data\n",
    "            real_imgs = torch.autograd.Variable(imgs.type(torch.Tensor)).cuda(CUDA)\n",
    "            \n",
    "            # Sampled noise\n",
    "            z = torch.autograd.Variable(torch.FloatTensor(np.random.normal(0,\n",
    "                                                                           1,\n",
    "                                                                           (imgs.shape[0],\n",
    "                                                                            latent_dim))).cuda(CUDA))\n",
    "        else:\n",
    "            # Adversarial ground truths\n",
    "            valid = torch.autograd.Variable(torch.FloatTensor(imgs.size(0),\n",
    "                                                              1).fill_(1.0),\n",
    "                                            requires_grad=False)\n",
    "            fake = torch.autograd.Variable(torch.FloatTensor(imgs.size(0),\n",
    "                                                             1).fill_(0.0),\n",
    "                                           requires_grad=False)\n",
    "\n",
    "            # Real data\n",
    "            real_imgs = torch.autograd.Variable(imgs.type(torch.Tensor))\n",
    "            \n",
    "            # Sampled noise\n",
    "            z = torch.autograd.Variable(torch.FloatTensor(np.random.normal(0,\n",
    "                                                                           1,\n",
    "                                                                           (imgs.shape[0],\n",
    "                                                                            latent_dim))))\n",
    "        \n",
    "        \n",
    "        # Generator Training\n",
    "        optimizer_G.zero_grad()\n",
    "            \n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Discriminator Training\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        epoch_g_loss += g_loss.float()\n",
    "        epoch_d_loss += d_loss.float()\n",
    "        \n",
    "        batches_done = epoch * len(train_loader) + batch_idx\n",
    "        if batches_done % 400 == 0:\n",
    "            save_image(gen_imgs.data[:49], 'images/%d.png' % batches_done, nrow=7, normalize=True)\n",
    "        \n",
    "    delta = time.time() - delta\n",
    "    print(f\"{delta:.2f} secs [Epoch {epoch}/{EPOCHS}] [D loss: {epoch_d_loss}] [G loss: {epoch_g_loss}]\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
